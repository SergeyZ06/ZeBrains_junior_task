**Задание:**

3. Разработать Веб-сервис similar-texts-recognition с помощью выбранного алгоритма.
- Для создания REST API можно использовать что удобно, FastApi, Flask, Django и т. п..
- В качестве алгоритма матчинга использовать косинусное расстояние или любой алгоритм кластеризации и любой NLP фреймворк.
- Достаточно одного REST эндпоинта POST /similar-recognition на вход которого подаётся два текста, на выходе получаем метрику схожести двух текстов в пределах от 0 до 1.
- Описать решение в README.md.
- Код запушить в GitHub и предоставить ссылку.
- Нужно будет объяснить, как работает сервис и выбранный алгоритм.

**Решение:**

Здравствуйте.

Для решения задачи разбора подобия текста мною были рассмотрены два направления:
- семантический разбор с помощью NLP библиотек для Python;
- лексический разбор текста с помощью библиотек векторизации текста.

Семантический разбор текста важнее лексического,
так как гораздо важнее определить смысловые сходства текстов,
нежели наличие символьного подобия в использованных словах.

Однако семантический разбор текста оказался гораздо сложнее лексического,
поэтому было решено использовать последний метод.

Далее для векторизации были рассмотрены три модели:
- CountVectorizer. Данная модель составляет словарь "знакомых" слов при обучении,
затем использует его для преставления строки в виде вектора, где в качестве координат
указаны количества вхождений "знакомых" слов;
- TfidfVectorizer. Данная модель работает аналогично первой, но использует инверсию
частоты вхождения слов для снижения влияния на векторизацию слов, которые встречаются
чаще остальных;
- HashingVectorizer. Данная модель использует хэш-функцию для построения вектора.

Выбор был сделан в пользу модели CountVectorizer, так как эта модель представляет
полностью интерпретируемый результат, что является преимуществом при отладке,
кастомизации модели и отчётности о её работе.

Для настройки модели CountVectorizer были использованы два подхода:
- stop_words, набор слов, которые модель должна игнорировать. Данный подход полезен,
так как позволяет исключить влияние слов, которые не несут существенной смысловой
нагрузки. В данном случае из разбора были исключены наиболее часто встречающиеся предлоги;
- unigrams и bigrams. Данных подход позволяет рассматривать не только слова индивидуально,
но и словосочетания слов, что может позволить выявить дополнительные различия. Например:
в сфере строительства словосочетания "подъёмный кран" и "водопроводный кран" будут
иметь различный смысл. Недостаток данного метода - увеличение размерности вектора из-за
наличия дополнительных координат словосочетаний. Поэтому было решено использовать
биграммы только для небольших текстов, до 30 слов.

Далее был использован фреймворк Flask для реализации REST API. Сервис принимает два параметра,
text_1 и text_2, две строки для анализа при помощи метода GET для отладки и при помощи метода POST
для штатной реализации. При этом GET возвращает читаемый человеком результат, html-документ,
POST - исключительно метрику.

Также был реализован модуль "test_request.py" для проверки работоспособности сервиса.
